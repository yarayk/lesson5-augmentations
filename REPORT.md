# 1

Была организована структура директорий с изображениями. Основные папки включают data/train/ для обучающего набора и data/test/ для тестового набора. Поскольку валидационный набор данных отсутствовал, была выполнена его генерация путём случайного разделения обучающего набора на две части: 80% для обучения и 20% для валидации. Это разделение осуществлялось с использованием функции random_split из PyTorch, что позволило создать два поднабора данных: train_dataset и val_dataset. Такой подход обеспечивает наличие всех необходимых выборок для обучения и оценки модели.

Результат применения каждой аугментации отдельно: Figure_1.png - Figure_8.png
Результат применения всех аугментаций вместе: Figure_9.png

task1_std_augs.py

# 2 

Были реализованы три кастомные аугментации изображений: случайное размытие, случайная перспектива и случайные изменения яркости и контрастности. Каждая из этих аугментаций была интегрирована в пайплайн обработки изображений и применена к данным обучающего набора. Результаты применения аугментаций были визуально проверены, и на основе полученных изображений были сделаны выводы о корректности и эффективности каждой аугментации. 

Результат применения каждой аугментации отдельно: Figure_10.png - Figure_13.png
Результат применения всех аугментаций вместе: Figure_14.png

task2_custom_augs.py

# 3
Количество изображений по классам:
Гароу: 30
Генос: 30
Сайтама: 30
Соник: 30
Татсумаки: 30
Фубуки: 30


Размеры изображений (ширина x высота):
Ширина — min: 210, max: 736, avg: 538.9
Высота — min: 240, max: 1308, avg: 623.6

Графики сохранены в папке `results/`

task3_dataset_analysis.py

# 4

Был создан класс AugmentationPipeline, включающий методы для добавления и удаления аугментаций, применения аугментаций к изображению и получения списка всех аугментаций. Были разработаны три конфигурации аугментаций: "light", включающая только флип; "medium", добавляющая к флипу обрезку и изменения яркости/контрастности; и "heavy", включающая все предыдущие аугментации, а также повороты и преобразования в оттенки серого. 
Каждая из этих конфигураций была применена к данным обучающего набора,
и результаты были сохранены для дальнейшего анализа в папку results

Processing profile 'light', augs: ['flip']
Processing profile 'medium', augs: ['flip', 'crop', 'jitter']
Processing profile 'heavy', augs: ['flip', 'crop', 'jitter', 'rotate', 'gray']

task4_pipeline.py

# 5

Проведён эксперимент с различными размерами изображений: 64x64, 128x128, 224x224 и 512x512. Для каждого размера было измерено время загрузки и применения аугментаций к 100 изображениям, а также потребление памяти. Результаты показали, что увеличение размера изображений приводит к увеличению времени обработки и потребления памяти. Графики зависимости времени и памяти от размера изображений были построены и сохранены в папке results/ для дальнейшего анализа.

Measuring size 64x64...
  time: 0.50s, mem Δ: 6.3 MB
Measuring size 128x128...
  time: 0.58s, mem Δ: 4.1 MB
Measuring size 224x224...
  time: 0.85s, mem Δ: 3.8 MB
Measuring size 512x512...
  time: 1.06s, mem Δ: 10.9 MB

Графики сохранены в `results/`

task5_size_experiment.py

# 6

В рамках дообучения предобученной модели ResNet18 была произведена замена последнего слоя на слой, соответствующий количеству классов в датасете. Модель была дообучена на данных обучающего набора, а её качество оценено на валидационном наборе. Визуализация процесса обучения показала динамику изменения функции потерь и точности модели по эпохам, что позволило оценить эффективность обучения и выявить возможные области для улучшения модели.

Train size: 144
Validation size: 36

task6_finetune.py